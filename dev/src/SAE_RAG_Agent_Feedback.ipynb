{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Colab Imports"
      ],
      "metadata": {
        "id": "YtVhicL1v7Pv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47R_NtxvsP4",
        "outputId": "64bbd061-e8c4-4cf2-9c95-aa6a6a60072f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "G1RjnwfawFp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langgraph langchain_openai langchain_community tiktoken konlpy langchain-pinecone pinecone-notebooks pyppeteer nest_asyncio pygraphviz"
      ],
      "metadata": {
        "id": "4c7bqFBc5D0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f3a38c-2768-4793-c00a-49409d924348"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
            "\u001b[0m  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pygraphviz \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pygraphviz\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Settings & Loadings"
      ],
      "metadata": {
        "id": "pFD3cE5ewHRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "PROFECT_DIR = os.path.join(\"/content/drive/MyDrive\", \"Profect SAE\")\n",
        "CSVs = os.path.join(PROFECT_DIR, \"test_data/CSVs\")\n",
        "files = os.listdir(CSVs)\n",
        "csv_files = [\n",
        "    file for file in files\n",
        "      if file.endswith(\".csv\")\n",
        "]\n",
        "\n",
        "df_one = pd.read_csv(os.path.join(CSVs, csv_files[0]))\n",
        "print(df_one.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpqOfVczwgq0",
        "outputId": "3e869fd4-6a22-4701-b570-6d2547de98da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title      [종합] 김태희, 해외서 권총 강도 당했다…'연매출 1100억' 정샘물 \"피해액 2...\n",
            "url        https://m.entertain.naver.com/article/312/0000...\n",
            "content    본문 바로가기 naver 엔터 뉴스 스포츠 사용자 링크 로그인 검색 홈 드라마 영화...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Things I need to do to add feedback loop\n",
        "\n",
        "1. New(or refactored) state and state management logic\n",
        "2. Applying Short-term memory for feedback: CheckPointer\n",
        "  - [LangGraph Memory](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
        "  - [LangGraph CheckPointer with InMemorySaver](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints)\n",
        "3. Modifying Generation Flows based on 5W1H below.\n",
        "  - Who?(Target): User\n",
        "  - When?: After stocks are generated and returned.\n",
        "  - Where?: (Feedback) Chrome Extension\n",
        "  - What?: Whether user liked it or not.\n",
        "  - How?: By adding a field at the state and use `InMemorySaver`\n",
        "  - Why?: To improve the result.\n",
        "\n",
        "4. Step By Step\n",
        "  - new state\n",
        "  - new Feedback Agent or modified RAG Agent\n",
        "  - (2025.04.28) Notes\n",
        "    - Preprocessing -> pass by dict\n",
        "    - RAG -> Save results, preprocessed, original? in `InMemorySaver`\n",
        "    - Feedback\n",
        "      - score -> for usage data\n",
        "      - regeneration"
      ],
      "metadata": {
        "id": "2gODsgWykyXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schema, DTO & State"
      ],
      "metadata": {
        "id": "bTbD1d11jSCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Schema\n",
        "- `Stock`"
      ],
      "metadata": {
        "id": "_hjtzkAno_3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "\n",
        "class Stock(BaseModel):\n",
        "  korean_name: str\n",
        "  english_name: str\n",
        "  market: str\n",
        "  ticker_code: str"
      ],
      "metadata": {
        "id": "73vONXSYo_W9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DTO\n",
        "- `StockGenRequestDto`\n",
        "- `FeedbackRequestDto`\n",
        "- `StockGenResponseDto`"
      ],
      "metadata": {
        "id": "NhW8ZNuklNNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "\n",
        "class StockGenRequestDto(BaseModel):\n",
        "  original_title: str = Field(..., min_length=1)\n",
        "  original_url: str = Field(..., min_length=5, max_length=2083)\n",
        "  original_content: str = Field(..., min_length=1)\n",
        "\n",
        "class FeedbackRequestDto(BaseModel):\n",
        "  state_id: str = Field(..., min_length=1)\n",
        "\n",
        "class StockGenResponseDto(BaseModel):\n",
        "  state_id: str = Field(..., min_length=1)\n",
        "  generated_stocks: list[Stock]"
      ],
      "metadata": {
        "id": "Xb-1suyEqTJh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### States\n",
        "- `PreprocessingFlowState`\n",
        "- `RAGFlowState`\n",
        "- `FlowState`: Pending"
      ],
      "metadata": {
        "id": "gtQkk7t8lReY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "\n",
        "class PreprocessingFlowState(BaseModel):\n",
        "  state_id: str = Field(..., min_length=1)\n",
        "  request_dto: StockGenRequestDto\n",
        "  route: str\n",
        "  preprocessed_title: str\n",
        "  preprocessed_url: str\n",
        "  preprocessed_content: str\n",
        "\n",
        "class RAGFlowState(BaseModel):\n",
        "  state_id: str = Field(..., min_length=1)\n",
        "  preprocessed_result: dict\n",
        "  response_dto: list[Stock]"
      ],
      "metadata": {
        "id": "-mRc40BglUvp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes"
      ],
      "metadata": {
        "id": "Tm_P4o8mxe7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "9FWQj0LkxiGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tools\n",
        "- `text_cleaning`"
      ],
      "metadata": {
        "id": "frPpZJe4Dia8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning(text: str) -> str:\n",
        "  \"\"\"Cleaning text by removing unnecessary characters and spaces.\"\"\"\n",
        "  if isinstance(text, str):\n",
        "      # Convert to lowercase\n",
        "      text = text.lower()\n",
        "      # Remove leading and trailing spaces\n",
        "      text = text.strip()\n",
        "      # Replace multiple spaces with a single space\n",
        "      text = re.sub(r'\\s+', ' ', text)\n",
        "      # Remove special characters except for common ones\n",
        "      text = re.sub(r'[^\\w\\s.,!?$%&@()-]', '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "svdRj-vPDveY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Router Node\n",
        "- `prerocessing_router_node`"
      ],
      "metadata": {
        "id": "_aDSc1QzPUt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocessing_router_node(preprocessing_flow_state: PreprocessingFlowState):\n",
        "  print(\"Routing\")\n",
        "  request_dto = preprocessing_flow_state.request_dto\n",
        "\n",
        "  youtube_pattern = r\"^https?://(www\\.)?youtube\\.com\"\n",
        "  naver_news_pattern = r\"^https?://n\\.news\\.naver\\.com\"\n",
        "  naver_entertainment_pattern = r\"^https?://m\\.entertain\\.naver\\.com\"\n",
        "  naver_sports_pattern = r\"^https?://m\\.sports\\.naver\\.com\"\n",
        "\n",
        "  if re.match(naver_news_pattern, request_dto.original_url):\n",
        "      route = \"naver_news\"\n",
        "\n",
        "  elif re.match(naver_entertainment_pattern, request_dto.original_url):\n",
        "      route = \"naver_entertainment\"\n",
        "\n",
        "  elif re.match(naver_sports_pattern, request_dto.original_url):\n",
        "      route = \"naver_sports\"\n",
        "\n",
        "  elif re.match(youtube_pattern, request_dto.original_url):\n",
        "      route = \"youtube\"\n",
        "  else:\n",
        "      route = \"default\"\n",
        "\n",
        "  # Basic text cleaning\n",
        "  preprocessing_flow_state.preprocessed_title = text_cleaning(request_dto.original_title)\n",
        "  preprocessing_flow_state.preprocessed_content = text_cleaning(request_dto.original_content)\n",
        "  preprocessing_flow_state.preprocessed_url = request_dto.original_url\n",
        "  preprocessing_flow_state.route = route\n",
        "  return preprocessing_flow_state"
      ],
      "metadata": {
        "id": "C4u9u9qpDv0Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing Nodes Based on `flow_state.preprocessing_flow_state.route`\n",
        "1. `naver_news_preprocessing_node`\n",
        "2. `naver_entertainment_preprocessing_node`\n",
        "3. `naver_sports_preprocessing_node`\n",
        "4. `youtube_preprocessing_node`\n",
        "5. `default_preprocessing_node`\n",
        "\n",
        "---\n",
        "\n",
        "1. `content_parser`"
      ],
      "metadata": {
        "id": "HR_gCULMDngN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def content_parser(text: str, remove_after: str = None, patterns: list = None) -> str:\n",
        "  if not isinstance(text, str):\n",
        "      return text\n",
        "\n",
        "  if remove_after:\n",
        "      text = re.sub(fr\"{remove_after}.*\", \"\", text, flags=re.IGNORECASE)\n",
        "\n",
        "  if patterns:\n",
        "    combined_pattern = \"|\".join(patterns)\n",
        "    text = re.sub(combined_pattern, \"\", text, flags=re.IGNORECASE)\n",
        "\n",
        "  # Remove excessive whitespace\n",
        "  text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "dCugrHGQAXOc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_naver_news_node(preprocessing_flow_state: PreprocessingFlowState):\n",
        "  print(\"NEWS\")\n",
        "  requestDto = preprocessing_flow_state.request_dto\n",
        "  \"\"\"Cleans Naver News content.\"\"\"\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"copyright .*?\\. all rights reserved\")\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"기사 공유하기\")\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, patterns = [\n",
        "          r\"본문 바로가기\", r\"naver\", r\"뉴스\", r\"엔터\", r\"스포츠\", r\"날씨\", r\"프리미엄\",\n",
        "          r\"사용자 링크\", r\"로그인\", r\"서비스\", r\"더보기\", r\"검색\", r\"언론사별\", r\"정치\",\n",
        "          r\"경제\", r\"사회\", r\"생활문화\", r\"it과학\", r\"세계\", r\"랭킹\", r\"신문보기\",\n",
        "          r\"오피니언\", r\"tv\", r\"팩트체크\", r\"알고리즘 안내\", r\"정정보도 모음\"])\n",
        "  return preprocessing_flow_state\n",
        "\n",
        "def preprocessing_naver_entertainment_node(preprocessing_flow_state: PreprocessingFlowState):\n",
        "  print(\"ENT\")\n",
        "  requestDto = preprocessing_flow_state.request_dto\n",
        "\n",
        "  \"\"\"Cleans Naver Entertainment content.\"\"\"\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"copyright .*?\\. all rights reserved\")\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"기사 공유하기\")\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, patterns = [\n",
        "      r\"본문 바로가기\", r\"naver\", r\"엔터\", r\"뉴스\", r\"스포츠\", r\"사용자 링크\", r\"로그인\",\n",
        "      r\"검색\", r\"홈\", r\"드라마\", r\"영화\", r\"뮤직\", r\"연애\", r\"포토\", r\"랭킹\", r\"최신뉴스\", r\"연재\", r\"종합\"])\n",
        "  return preprocessing_flow_state\n",
        "\n",
        "def preprocessing_naver_sports_node(preprocessing_flow_state: PreprocessingFlowState):\n",
        "  print(\"SPORTS\")\n",
        "  requestDto = preprocessing_flow_state.request_dto\n",
        "  \"\"\"Cleans Naver Sports content.\"\"\"\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"copyright .*?\\. all rights reserved\")\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"기사 공유하기\")\n",
        "  return preprocessing_flow_state\n",
        "\n",
        "def preprocessing_youtube_node(preprocessing_flow_state: PreprocessingFlowState):\n",
        "  print(\"YOUTUBE\")\n",
        "  requestDto = preprocessing_flow_state.request_dto\n",
        "  \"\"\"Cleans YouTube transcript content.\"\"\"\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, remove_after=\"더보기\")\n",
        "  preprocessing_flow_state.preprocessed_content = content_parser(requestDto.original_content, patterns = [r\"kr\", r\"탐색\", r\"건너뛰기\", r\"만들기\"])\n",
        "  return preprocessing_flow_state"
      ],
      "metadata": {
        "id": "YJENNr17h1YA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG"
      ],
      "metadata": {
        "id": "ktRg-jmb_ETD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nodes"
      ],
      "metadata": {
        "id": "T9ZCX2wt_LM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import tiktoken\n",
        "\n",
        "pc = Pinecone(api_key=userdata.get('PINECONE-API-KEY'))\n",
        "\n",
        "\n",
        "def retriever_init(index_name: str, embeddings, namespace):\n",
        "  index = pc.Index(index_name)\n",
        "  vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "  return vector_store.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\"k\": 2, \"score_threshold\": 0.65,\"namespace\": namespace},)\n",
        "\n",
        "def retrieved_vector_parser(given_vectors, market_name=\"N/A\"):\n",
        "    return [\n",
        "        Stock(\n",
        "            korean_name=vector.metadata.get(\"korean_name\", \"N/A\"),\n",
        "            english_name=vector.metadata.get(\"english_name\", \"N/A\"),\n",
        "            ticker_code=vector.metadata.get(\"ticker_code\", \"N/A\"),\n",
        "            market=market_name\n",
        "        )\n",
        "        for vector in given_vectors\n",
        "    ]\n",
        "\n",
        "def retriever_node(rag_flow_state: RAGFlowState):\n",
        "  text = f\"{rag_flow_state.preprocessed_result['title']}  {rag_flow_state.preprocessed_result['content']}\"\n",
        "\n",
        "  # Vector Store init\n",
        "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "  kor_retriever = retriever_init(\"sae-embedded-stocks-kor\", embeddings, \"kospi-900\")\n",
        "  foriegn_retriever = retriever_init(\"sae-embedded-stocks-foriegn\", embeddings, \"nasdaq-1000\")\n",
        "\n",
        "  # Invoke\n",
        "  kor_result = retrieved_vector_parser(kor_retriever.invoke(text), \"KOSPI\")\n",
        "  foriegn_result = retrieved_vector_parser(foriegn_retriever.invoke(text),\"NASDAQ\")\n",
        "  rag_flow_state.response_dto.extend(kor_result)\n",
        "  rag_flow_state.response_dto.extend(foriegn_result)\n",
        "  return rag_flow_state"
      ],
      "metadata": {
        "id": "wVkPqGWq_QJV"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feedback"
      ],
      "metadata": {
        "id": "Dn5ooFAH--pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nodes"
      ],
      "metadata": {
        "id": "wCDe7el4_R8n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIdAlAUp_RJQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flow"
      ],
      "metadata": {
        "id": "sxGbY-eMzD7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Flow"
      ],
      "metadata": {
        "id": "BGau14VFGWzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "preprocessing_graph = StateGraph(state_schema=PreprocessingFlowState)\n",
        "\n",
        "# Registering Noes\n",
        "\n",
        "## router\n",
        "preprocessing_graph.add_node(\"preprocessing_router_node\", preprocessing_router_node)\n",
        "\n",
        "## preprocessing\n",
        "preprocessing_graph.add_node(\"naver_news_preprocessing_node\", preprocessing_naver_news_node)\n",
        "preprocessing_graph.add_node(\"naver_entertainment_preprocessing_node\", preprocessing_naver_entertainment_node)\n",
        "preprocessing_graph.add_node(\"naver_sports_preprocessing_node\", preprocessing_naver_sports_node)\n",
        "preprocessing_graph.add_node(\"youtube_preprocessing_node\", preprocessing_youtube_node)\n",
        "\n",
        "\n",
        "# Registering Edges\n",
        "# Conditional Edges\n",
        "preprocessing_graph.add_edge(START, \"preprocessing_router_node\")\n",
        "\n",
        "preprocessing_graph.add_conditional_edges(\n",
        "    \"preprocessing_router_node\",\n",
        "    lambda flow_state: flow_state.route,\n",
        "    {\n",
        "        \"naver_news\": \"naver_news_preprocessing_node\",\n",
        "        \"naver_entertainment\": \"naver_entertainment_preprocessing_node\",\n",
        "        \"naver_sports\": \"naver_sports_preprocessing_node\",\n",
        "        \"youtube\": \"youtube_preprocessing_node\",\n",
        "        \"default\": END,\n",
        "    }\n",
        ")\n",
        "\n",
        "preprocessing_graph.add_edge(\"naver_news_preprocessing_node\", END)\n",
        "preprocessing_graph.add_edge(\"naver_entertainment_preprocessing_node\", END)\n",
        "preprocessing_graph.add_edge(\"naver_sports_preprocessing_node\", END)\n",
        "preprocessing_graph.add_edge(\"youtube_preprocessing_node\", END)\n",
        "\n",
        "# agent Init\n",
        "preprocessing_agent = preprocessing_graph.compile()"
      ],
      "metadata": {
        "id": "3V_HZIg6AZyf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization: Preprocessing Flow"
      ],
      "metadata": {
        "id": "Livo7qjRzaXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize your graph\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(Image(preprocessing_agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "Hf1PkmvyzfDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Flow"
      ],
      "metadata": {
        "id": "TWqK-1b54vK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "rag_graph = StateGraph(state_schema=RAGFlowState)\n",
        "\n",
        "# Registring Nodes\n",
        "rag_graph.add_node(\"retriever_node\", retriever_node)\n",
        "\n",
        "# Registering Edges\n",
        "rag_graph.add_edge(START, \"retriever_node\")\n",
        "rag_graph.add_edge(\"retriever_node\", END)\n",
        "\n",
        "rag_agent = rag_graph.compile()"
      ],
      "metadata": {
        "id": "_Y_GjJhA4utT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization: RAG Flow"
      ],
      "metadata": {
        "id": "o5TILKA06dVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize your graph\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(Image(rag_agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "ROSew0jD6dBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tesing Agents"
      ],
      "metadata": {
        "id": "aNfI00XIlYmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Preprocessing Agents"
      ],
      "metadata": {
        "id": "eUD-tO4Sz0BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import time\n",
        "\n",
        "for row in df_one.itertuples(index=False):\n",
        "  start = time.time()\n",
        "  # Preprocessing\n",
        "  ## State Init\n",
        "  stock_gen_request_dto = StockGenRequestDto(\n",
        "      original_title=row.title,\n",
        "      original_url=row.url,\n",
        "      original_content=row.content\n",
        "  )\n",
        "\n",
        "  preprocessing_flow_state = PreprocessingFlowState(\n",
        "      state_id=\"test\",\n",
        "      request_dto=stock_gen_request_dto,\n",
        "      route=\"\",\n",
        "      preprocessed_title=\"\",\n",
        "      preprocessed_url=\"\",\n",
        "      preprocessed_content=\"\")\n",
        "\n",
        "  print(\"Title: \", preprocessing_flow_state.request_dto.original_title + \"\\n\")\n",
        "  print(\"Preprocessing Agent\")\n",
        "  preprocessed_result = preprocessing_agent.invoke(preprocessing_flow_state)\n",
        "  before_length = len(preprocessed_result['request_dto'].original_content)\n",
        "  after_length = len(preprocessed_result['preprocessed_content'])\n",
        "  print(\"Before: \"+str(before_length))\n",
        "  print(\"After: \" +str(after_length))\n",
        "  print(\"\")\n",
        "\n",
        "  print(\"RAG Agent\")\n",
        "  rag_flow_state = RAGFlowState(\n",
        "      state_id=preprocessed_result['state_id'],\n",
        "      preprocessed_result={\n",
        "          \"title\": preprocessed_result['preprocessed_title'],\n",
        "          \"url\": preprocessed_result['preprocessed_url'],\n",
        "          \"content\": preprocessed_result['preprocessed_content']\n",
        "      },\n",
        "      response_dto=[]\n",
        "  )\n",
        "  rag_result = rag_agent.invoke(rag_flow_state)\n",
        "  print(\"Retrieved stocks\")\n",
        "  for stock in rag_result['response_dto']:\n",
        "    print(stock.korean_name, stock.english_name, stock.market, stock.ticker_code)\n",
        "  elapsed = time.time() - start\n",
        "  print(\"\")\n",
        "  print(f\"Elapsed Time: {elapsed:.2f} seconds\")\n",
        "  print(\"---------------------------\")\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjxFkM3BldJn",
        "outputId": "7f3cb1c6-ea52-41de-f104-fb30aeb0f14c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title:  [종합] 김태희, 해외서 권총 강도 당했다…'연매출 1100억' 정샘물 \"피해액 2000만원\"('백억짜리')\n",
            "\n",
            "Preprocessing Agent\n",
            "Routing\n",
            "ENT\n",
            "Before: 2678\n",
            "After: 2526\n",
            "\n",
            "RAG Agent\n",
            "Retrieved stocks\n",
            "티와이홀딩스 TY HOLDINGS KOSPI 363280\n",
            "시프트업 SHIFT UP KOSPI 462870\n",
            "울타 뷰티 Ulta Beauty Inc NASDAQ ULTA\n",
            "타불라 Taboola.com Ltd NASDAQ TBLA\n",
            "\n",
            "Elapsed Time: 2.56 seconds\n",
            "---------------------------\n"
          ]
        }
      ]
    }
  ]
}